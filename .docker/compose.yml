version: '3.7'
name: pulsar-telemetry
# https://pulsar.apache.org/docs/3.1.x/getting-started-docker-compose/
networks:
  pulsar:
    driver: bridge
services:
  # Start zookeeper
  zookeeper:
    image: apachepulsar/pulsar:latest
    container_name: zookeeper
    restart: on-failure
    networks:
      - pulsar
    volumes:
      - ./data/zookeeper:/pulsar/data/zookeeper
    environment:
      - metadataStoreUrl=zk:zookeeper:2181
      - PULSAR_MEM=-Xms256m -Xmx256m -XX:MaxDirectMemorySize=256m
    command: >
      bash -c "bin/apply-config-from-env.py conf/zookeeper.conf && \
             bin/generate-zookeeper-config.sh conf/zookeeper.conf && \
             exec bin/pulsar zookeeper"
    healthcheck:
      test: ["CMD", "bin/pulsar-zookeeper-ruok.sh"]
      interval: 10s
      timeout: 5s
      retries: 30

  # Init cluster metadata
  pulsar-init:
    container_name: pulsar-init
    hostname: pulsar-init
    image: apachepulsar/pulsar:latest
    networks:
      - pulsar
    command: >
      bin/pulsar initialize-cluster-metadata \
               --cluster cluster-a \
               --zookeeper zookeeper:2181 \
               --configuration-store zookeeper:2181 \
               --web-service-url http://broker:8080 \
               --broker-service-url pulsar://broker:6650
    depends_on:
      zookeeper:
        condition: service_healthy

  # Start bookie
  bookie:
    image: apachepulsar/pulsar:latest
    container_name: bookie
    restart: on-failure
    networks:
      - pulsar
    environment:
      - clusterName=cluster-a
      - zkServers=zookeeper:2181
      - metadataServiceUri=metadata-store:zk:zookeeper:2181
      # otherwise every time we run docker compose uo or down we fail to start due to Cookie
      # See: https://github.com/apache/bookkeeper/blob/405e72acf42bb1104296447ea8840d805094c787/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Cookie.java#L57-68
      - advertisedAddress=bookie
      - BOOKIE_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m
    depends_on:
      zookeeper:
        condition: service_healthy
      pulsar-init:
        condition: service_completed_successfully
    # Map the local directory to the container to avoid bookie startup failure due to insufficient container disks.
    volumes:
      - ./data/bookkeeper:/pulsar/data/bookkeeper
    command: bash -c "bin/apply-config-from-env.py conf/bookkeeper.conf && exec bin/pulsar bookie"

  # Start broker
  broker:
    image: apachepulsar/pulsar:latest
    container_name: broker
    hostname: broker
    restart: on-failure
    networks:
      - pulsar
    environment:
      - metadataStoreUrl=zk:zookeeper:2181
      - zookeeperServers=zookeeper:2181
      - clusterName=cluster-a
      - managedLedgerDefaultEnsembleSize=1
      - managedLedgerDefaultWriteQuorum=1
      - managedLedgerDefaultAckQuorum=1
      - advertisedAddress=broker
      - advertisedListeners=external:pulsar://127.0.0.1:6650
      - PULSAR_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m
    depends_on:
      zookeeper:
        condition: service_healthy
      bookie:
        condition: service_started
    ports:
      - "6650:6650"
      - "8080:8080"
    command: bash -c "bin/apply-config-from-env.py conf/broker.conf && exec bin/pulsar broker"

  jaeger:
    image: jaegertracing/opentelemetry-all-in-one
    container_name: jaeger-pulsar
    networks:
      - pulsar
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - 16686:16686
      - 4318:4318
      - 4317:4317
    restart: unless-stopped
  prometheus:
    image: prom/prometheus
    container_name: prometheus-pulsar
    networks:
      - pulsar
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - 9090:9090
    restart: unless-stopped
    volumes:
      - ./prometheus:/etc/prometheus
      - prom_data:/prometheus
  grafana:
    image: grafana/grafana
    container_name: grafana-pulsar
    networks:
      - pulsar
    ports:
      - 3000:3000
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana:/etc/grafana/provisioning/datasources
      - ./grafana/dashboard.yaml:/etc/grafana/provisioning/dashboards/main.yaml
      - ./grafana/dashboards:/var/lib/grafana/dashboards


  redis:
    image: redis:6.2-alpine
    # image: redis:6.2
    container_name: redis
  
    # restart: always
    restart: unless-stopped
    ports:
      - 6379:6379
    # command: redis-server --save 20 1 --loglevel warning --requirepass YOUR_PASS
    command: redis-server --loglevel warning 
    volumes: 
      - redis:/data

  # # https://docs.localstack.cloud/getting-started/installation/#docker-compose
  # localstack:
  #   container_name: "${LOCALSTACK_DOCKER_NAME:-localstack-main}"
  #   image: localstack/localstack
  #   ports:
  #     - 4566:4566            # LocalStack Gateway
  #     # - 4510-4559:4510-4559  # external services port range
  #   environment:
  #     # LocalStack configuration: https://docs.localstack.cloud/references/configuration/
  #     SERVICES: s3
  # #    # SERVICES: firehose,kinesis,lambda,s3,sqs,dynamodb
  #     # SERVICES: firehose,kinesis,lambda,s3,sqs,dynamodb
  #     AWS_DEFAULT_REGION: us-east-1
  #     DEBUG: ${DEBUG:-0}
  #   volumes:
  #     - "${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack"
  #     - "/var/run/docker.sock:/var/run/docker.sock"

  mongo:
    image: "${LOCALSTACK_DOCKER_NAME:-mongo}"
    # restart: always
    # restart: on-failure
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    volumes: 
      - mongo:/data

  mongo-express:
    image: mongo-express
    restart: always
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/
      
volumes:
  prom_data:
  redis:
    driver: local
  localstack:
  mongo: